{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KIMWONGYU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make torch\n",
    "def make_variables(sentences, label,vocabulary):\n",
    "    \n",
    "    final_sentences = []\n",
    "    \n",
    "    #tokenizing\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        final_sentences.append(nltk.word_tokenize(sentence))\n",
    "    \n",
    "    #indexing\n",
    "    for index, sentence in enumerate(final_sentences):\n",
    "        final_sentences[index]=[vocabulary[word] for word in sentence]\n",
    "\n",
    "    #각자의 seq_length 구하기 (미니배치별로 진행)\n",
    "    seq_lengths = []\n",
    "    for sentence in final_sentences:\n",
    "        seq_lengths.append(len(sentence))\n",
    "    seq_lengths = torch.LongTensor(seq_lengths)\n",
    "\n",
    "#     print(\"패딩전\")\n",
    "#     print(final_sentences[:5])\n",
    "#     print(seq_lengths[:5])\n",
    "#     print(label[:5])\n",
    "    return padding_tensor_sorting(final_sentences,seq_lengths,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tensor_sorting(sentences, seq_lengths, label):\n",
    "    seq_tensor = torch.zeros((len(sentences), seq_lengths.max())).long()\n",
    "    print('seq_tensor(max):' , seq_lengths.max())\n",
    "    for idx, (seq, seq_len) in enumerate(zip(sentences, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "    \n",
    "    if len(seq_tensor) !=1:\n",
    "        seq_lengths, perm_idx = seq_lengths.sort(0,descending=True)\n",
    "        seq_tensor = seq_tensor[perm_idx]\n",
    "    \n",
    "    \n",
    "    target = torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    if len(seq_tensor) !=1 and len(target)!=0:\n",
    "        target = target[perm_idx]\n",
    "        \n",
    "#     print(\"패딩후\")\n",
    "#     print(seq_tensor[:5])\n",
    "#     print(seq_lengths[:5])\n",
    "#     print(target[:5])\n",
    "    return create_variable(seq_tensor), \\\n",
    "        create_variable(seq_lengths), \\\n",
    "        create_variable(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable(tensor):\n",
    "    #tensor를 gpu 이용 가능한지\n",
    "    if torch.cuda.is_available():\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_test(sentence,a1,a2,a3,a4):\n",
    "\n",
    "    raw_data = []\n",
    "    sentences = []\n",
    "    \n",
    "    temp =[]\n",
    "    temp.append(sentence)\n",
    "    temp.append(a1)\n",
    "    temp.append(a2)\n",
    "    temp.append(a3)\n",
    "    temp.append(a4)\n",
    "    raw_data.append(temp)\n",
    "    \n",
    "    print(\"총 문제 개수: \", len(raw_data))\n",
    "    print(\"총 문장 개수: \", len(raw_data)*4)\n",
    "    for row_index, row in enumerate(raw_data):\n",
    "        row_sentence = []\n",
    "        row_label = []\n",
    "        hype1 = 0\n",
    "        hype2 = 0\n",
    "        for item_index, item in enumerate(row):\n",
    "            # .뒤에 나오는 것 다 없애기 .이 여러 개 있을지 모르니 마지막 .을 이용하기. 두 문장인 경우 .과 ?과 !이 존재\n",
    "            # 특수문자 앞에 공백으로 하기\n",
    "            # 공백 없애기\n",
    "            # 공백 두개, 세개 -> 한개로 바꾸기\n",
    "            # _____,----- 연달아 있을시 index 찾아 양쪽 공백 만들기\n",
    "            # 소문자로 바꾸기\n",
    "\n",
    "            if item_index == 0:\n",
    "                #\n",
    "                index_list = []\n",
    "                index_of_dot = item.rfind('.')\n",
    "                index_of_question = item.rfind('?')\n",
    "                index_of_surprise = item.rfind('!')\n",
    "                index_list.append(index_of_dot)\n",
    "                index_list.append(index_of_question)\n",
    "                index_list.append(index_of_surprise)\n",
    "                standard = max(index_list)+1\n",
    "                if standard >0:\n",
    "                    item = item[:standard]   \n",
    "\n",
    "                #\n",
    "                item = item.strip()\n",
    "                #\n",
    "                item = item.replace(\"  \", \" \")\n",
    "                item = item.replace(\"  \", \" \")\n",
    "\n",
    "                #\n",
    "                index_of_hype1 = item.find('__')\n",
    "                index_of_hype2 = item.find('--')\n",
    "                index_of_hype3 = item.rfind('__')\n",
    "                index_of_hype4 = item.rfind('--')\n",
    "                if index_of_hype1 > index_of_hype2:\n",
    "                    if index_of_hype3 > index_of_hype4:\n",
    "                        hype1 = index_of_hype1\n",
    "                        hype2 = index_of_hype3+1\n",
    "                elif index_of_hype2 > index_of_hype1:\n",
    "                    if index_of_hype4 > index_of_hype3:\n",
    "                        hype1 = index_of_hype2\n",
    "                        hype2 = index_of_hype4+1\n",
    "\n",
    "                #----- => hype1 = 0 , hype2 = 4\n",
    "                if hype1 == 0:\n",
    "                    if (hype2+1) < len(item):\n",
    "                        if item[hype2+1] != ' ':\n",
    "                            item = item[:hype2+1] + ' ' + item[hype2+1:]\n",
    "                else:\n",
    "                    if item[hype1-1] != ' ':\n",
    "                        item = item[:hype1] + ' ' + item[hype1:]\n",
    "                        hype1 = hype1+1\n",
    "                        hype2 = hype2+1\n",
    "                    if (hype2+1) < len(item):\n",
    "                        if item[hype2+1] != ' ':\n",
    "                            item = item[:hype2+1] + ' ' + item[hype2+1:]\n",
    "                #\n",
    "                item = item.lower()\n",
    "                # 문장이 아닐 때\n",
    "            else:\n",
    "                 item = item.strip()\n",
    "            raw_data[row_index][item_index] = item\n",
    "        #sentence 4개 만들기\n",
    "        row[0] = row[0].replace(row[0][hype1:hype2+1],\"\")\n",
    "        for i in range(1,5):\n",
    "            sentence = row[0][:hype1] + row[i] + row[0][hype1:]\n",
    "            row_sentence.append(sentence)\n",
    "\n",
    "        sentences.append(row_sentence)\n",
    "\n",
    "    sentences= np.array(sentences)\n",
    "    sentences= sentences.flatten()\n",
    "    sentences = sentences.tolist()\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, bidirectional=True ,dropout_p=0.2):\n",
    "        super(myModel, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_vocab = n_vocab\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.n_directions = int(bidirectional) + 1\n",
    "        \n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "#         self.lstm = nn.LSTM(self.embed_dim, self.hidden_dim,\n",
    "#                             num_layers=self.n_layers,\n",
    "#                             dropout=dropout_p,\n",
    "#                             batch_first=True)\n",
    "        self.lstm = nn.GRU(self.embed_dim, self.hidden_dim,\n",
    "                            self.n_layers,\n",
    "                            #dropout=dropout_p,\n",
    "                            batch_first=True)\n",
    "#         self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(self.hidden_dim, self.n_classes)\n",
    "#         self.fc1 = nn.Linear(self.hidden_dim, 50)\n",
    "#         self.fc2 = nn.Linear(50, self.n_classes)\n",
    "    def forward(self, x, seq_lengths):\n",
    "        \n",
    "        x = x.t()\n",
    "        sen_len = x.size(0)\n",
    "        batch_size = x.size(1)\n",
    "        print(self.n_layers, self.hidden_dim, self.n_vocab, self.embed_dim, self.n_classes, self.n_directions)\n",
    "        \n",
    "        print(x)\n",
    "        embedded = self.embed(x)\n",
    "        \n",
    "#         print(embedded)\n",
    "        lstm_input = pack_padded_sequence(embedded, seq_lengths.data.cpu().numpy())\n",
    "        self.hidden = self._init_hidden(batch_size)\n",
    "        self.lstm.flatten_parameters()\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(lstm_input)\n",
    "        lstm_out, lengths = pad_packed_sequence(lstm_out)\n",
    "        \n",
    "#         h_t = self.dropout(self.hidden[-1])\n",
    "#         logit = self.out(h_t[-1])\n",
    "        logit = self.out(self.hidden[-1])\n",
    "#         print(logit)\n",
    "        return logit\n",
    "    \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros((self.n_layers, self.n_directions,\n",
    "                             batch_size, self.hidden_dim))\n",
    "        return create_variable(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_problem_test(sentence, a1,a2,a3,a4):\n",
    "    \n",
    "    sentences = pre_process_test(sentence,a1,a2,a3,a4)\n",
    "    \n",
    "    print(sentences)\n",
    "    \n",
    "    #단어집 불러오기\n",
    "    file = open(\"vocabulary\", \"rb\")\n",
    "    vocabulary = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    vocab = set()\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        temp = nltk.word_tokenize(sentence)\n",
    "        vocab.update(temp)\n",
    "    vocab.update(vocabulary)\n",
    "    \n",
    "    word_to_ix_t = {word:i+2 for i, word in enumerate(vocab)}\n",
    "    word_to_ix_t['_PAD'] = 0\n",
    "    word_to_ix_t['_UNK'] = 1\n",
    "    vocabsize_t = len(word_to_ix_t)\n",
    "    #모델 부르기\n",
    "    test_model = torch.load('saved_gru')\n",
    "    test_model.n_vocab = vocabsize_t\n",
    "    test_model.embed = nn.Embedding(test_model.n_vocab, test_model.embed_dim)\n",
    "    \n",
    "    input, seq_lengths, target = make_variables(sentences,[],word_to_ix_t)\n",
    "    \n",
    "    output = test_model(input,seq_lengths)\n",
    "    pred = output.data.max(1,keepdim=True)[1]\n",
    "    print(\"softmax 직후...\", output)\n",
    "    print(\"1개만 고른후...\", pred)\n",
    "    print(\"pred\",pred)\n",
    "    print(pred[1][0])\n",
    "    answers = []\n",
    "    answers.append(a1)\n",
    "    answers.append(a2)\n",
    "    answers.append(a3)\n",
    "    answers.append(a4)\n",
    "    \n",
    "    print(answers)\n",
    "    one_indice = []\n",
    "    \n",
    "    for i, pred_item in enumerate(pred):\n",
    "        if pred_item[0] == 1:\n",
    "            one_indice.append(i)\n",
    "    if len(one_indice) == 1:\n",
    "        return answers[one_dice[0]]\n",
    "    elif len(one_indice)==0:\n",
    "        result_list = []\n",
    "        for i in range(0,4):\n",
    "            result_list.append(pred[index][0])\n",
    "        return answers[result_list.index(max(result_list))]\n",
    "    else:\n",
    "        index_list = []\n",
    "        result_list = []\n",
    "        for index in one_indice:\n",
    "            index_list.append(index)\n",
    "            result_list.append(pred[index][0])\n",
    "        return answers[index_list[max(result_list)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문제 개수:  1\n",
      "총 문장 개수:  4\n",
      "['improve harvesting techniques have been instrumental in helping many of the local small farmers to become more self-sufficient.', 'improved harvesting techniques have been instrumental in helping many of the local small farmers to become more self-sufficient.', 'improvement harvesting techniques have been instrumental in helping many of the local small farmers to become more self-sufficient.', 'improves harvesting techniques have been instrumental in helping many of the local small farmers to become more self-sufficient.']\n",
      "seq_tensor(max): tensor(19)\n",
      "2 100 133634 64 2 2\n",
      "tensor([[ 1.3308e+05,  1.3019e+05,  1.3027e+05,  1.1645e+05],\n",
      "        [ 1.1689e+05,  1.1689e+05,  1.1689e+05,  1.1689e+05],\n",
      "        [ 1.0571e+05,  1.0571e+05,  1.0571e+05,  1.0571e+05],\n",
      "        [ 2.3332e+04,  2.3332e+04,  2.3332e+04,  2.3332e+04],\n",
      "        [ 1.2347e+05,  1.2347e+05,  1.2347e+05,  1.2347e+05],\n",
      "        [ 2.4350e+03,  2.4350e+03,  2.4350e+03,  2.4350e+03],\n",
      "        [ 1.1615e+05,  1.1615e+05,  1.1615e+05,  1.1615e+05],\n",
      "        [ 5.1456e+04,  5.1456e+04,  5.1456e+04,  5.1456e+04],\n",
      "        [ 2.0538e+04,  2.0538e+04,  2.0538e+04,  2.0538e+04],\n",
      "        [ 6.0611e+04,  6.0611e+04,  6.0611e+04,  6.0611e+04],\n",
      "        [ 1.2156e+05,  1.2156e+05,  1.2156e+05,  1.2156e+05],\n",
      "        [ 5.7434e+04,  5.7434e+04,  5.7434e+04,  5.7434e+04],\n",
      "        [ 5.3149e+04,  5.3149e+04,  5.3149e+04,  5.3149e+04],\n",
      "        [ 1.2500e+03,  1.2500e+03,  1.2500e+03,  1.2500e+03],\n",
      "        [ 3.3228e+04,  3.3228e+04,  3.3228e+04,  3.3228e+04],\n",
      "        [ 5.3758e+04,  5.3758e+04,  5.3758e+04,  5.3758e+04],\n",
      "        [ 2.4883e+04,  2.4883e+04,  2.4883e+04,  2.4883e+04],\n",
      "        [ 6.5655e+04,  6.5655e+04,  6.5655e+04,  6.5655e+04],\n",
      "        [ 6.4311e+04,  6.4311e+04,  6.4311e+04,  6.4311e+04]])\n",
      "softmax 직후... tensor([[ 1.2956, -1.3175],\n",
      "        [-0.2967, -0.1149],\n",
      "        [-0.3519,  0.8862],\n",
      "        [-0.1040,  0.0750]])\n",
      "1개만 고른후... tensor([[ 0],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 1]])\n",
      "pred tensor([[ 0],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 1]])\n",
      "tensor(1)\n",
      "[' improve', 'improved', 'improvement', 'improves']\n",
      "정답!!!!= improvement\n"
     ]
    }
   ],
   "source": [
    "return_num = one_problem_test('____________ harvesting techniques have been instrumental in helping many of the local small farmers to become more self-sufficient. ',\n",
    "                    ' improve', 'improved', 'improvement', 'improves')\n",
    "\n",
    "print(\"정답!!!!=\", return_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d', 's'}\n"
     ]
    }
   ],
   "source": [
    "a = ['s','d']\n",
    "v = set()\n",
    "v.update(a)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
